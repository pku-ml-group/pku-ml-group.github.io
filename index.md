---
layout: default
---
PKU-ML group advised by [Yuan Li](https://yuanli2333.github.io/) mainly focus on machine learning, reinforcement learning, active learning, data-centric AL, LLMs and so on.
## 2023 FALL
- **[2023-09-01]** LLMs Attacks: Universal and Transferable Adversarial Attacks on Aligned Language Models. [[pdf](./ppt/20230901-LLMs-Attacker.pdf)] Zhen-Hui Liu
- **[2023-09-08]** On Calibration of Modern Neural Networks. [[pdf](./ppt/20230908_Model%20Calibration.pdf)] Kun-Peng Ning
- **[2023-09-15]** AutoPrompt: Eliciting Knowledge from Language Models with Automatically Generated Prompts. [[pdf](./ppt/20230915-AutoPrompt.pdf)] Jia-Yu Yao
- **[2023-09-22]** SAM: Segment Anything. [[pdf](./ppt/20230922-SAM.pdf)] Hai-Jian Ke
- **[2023-10-13]** Black Box Adversarial Attack. [[pdf](./ppt/20231013-blackbox.pdf)] Zhen-Hui Liu
- **[2023-10-20]** Black Box Adversarial Attack on Text Classification. [[pdf](./ppt/20231020-BlackBoxAdversarialAttacksonText.pdf)] Kun-Peng Ning
- **[2023-10-27]** Reinforcement Learning to Attack Based LLM Evaluation. [[pdf](./ppt/20231027-Reinforcement%20Learning%20%20to%20Attack%20Based%20LLM%20Evaluation.pdf)] Jia-Yu Yao
- **[2023-11-03]** Class incremental learning. [[pdf](./ppt/20231105-class_incremental_learning.pdf)] Hai-Jian Ke
- **[2023-11-10]** Prompt tuning survey. [[pdf](./ppt/20231110-prompt_tuning_survey.pdf)] Shuo Yang
- **[2023-11-17]** LLM Evaluation. [[pdf](./ppt/20231117-llm_evaluation.pdf)] Zhen-Hui Liu
- **[2023-11-24]** Edit Large Language Models. [[pdf](./ppt/20231124-Edit_Large_language_model.pdf)] Yu Wang
